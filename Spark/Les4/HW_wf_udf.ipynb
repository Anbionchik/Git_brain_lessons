{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install pyspark"
      ],
      "metadata": {
        "id": "TLeTWw0yKfdA",
        "outputId": "a58250a4-3da2-4415-a3cd-fc443745f191",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: pyspark in /usr/local/lib/python3.10/dist-packages (3.4.0)\n",
            "Requirement already satisfied: py4j==0.10.9.7 in /usr/local/lib/python3.10/dist-packages (from pyspark) (0.10.9.7)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql import functions as F\n",
        "from pyspark.sql.types import *"
      ],
      "metadata": {
        "id": "d6jiq3kyQhEB"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E3Q9g_UyNxS6"
      },
      "source": [
        "from pyspark.sql import SparkSession\n",
        "spark = SparkSession.builder\\\n",
        "    .master(\"local[2]\")\\\n",
        "    .appName(\"Lesson_2\")\\\n",
        "    .config(\"spark.executor.instances\",2)\\\n",
        "    .config(\"spark.executor.memory\",'2g')\\\n",
        "    .config(\"spark.executor.cores\",1)\\\n",
        "    .getOrCreate()\n",
        "sc = spark.sparkContext"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df = spark.read.load('raw_sales.csv', format='csv', header=True, inferSchema=True)"
      ],
      "metadata": {
        "id": "TTrYZ5IpOuj6"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for row in df.schema:\n",
        "  print(row)"
      ],
      "metadata": {
        "id": "nO3uoQClPIHU",
        "outputId": "8c78991a-bfd8-4871-aad1-07a7ba2fc299",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "StructField('datesold', TimestampType(), True)\n",
            "StructField('postcode', IntegerType(), True)\n",
            "StructField('price', IntegerType(), True)\n",
            "StructField('propertyType', StringType(), True)\n",
            "StructField('bedrooms', IntegerType(), True)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dVGNGR7pN1KC"
      },
      "source": [
        "# Самостоятельная работа к уроку 4\n",
        "На уроке мы попробовали оконные и пользовательские функции. Теперь закрепим полученные знания."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "agigNChqOHnK"
      },
      "source": [
        "## Данные: [google drive: raw_sales.csv](https://drive.google.com/file/d/1G2N7Mnt4-Tqz4JdJxutGDMbJiOr32kZp/view?usp=sharing)\n",
        "\n",
        " Каждая строчка это продажа жилья, которая состоит из следующих полей (думаю описание не требуется):\n",
        "*   date of sale\n",
        "*   price\n",
        "*   property type\n",
        "*   number of bedrooms\n",
        "*   4digit postcode"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xisyFowtQgx-"
      },
      "source": [
        "## Задание 1\n",
        "Добавьте к таблице следующие поля:\n",
        "*  Средняя стомость 10 проданных домов до текущего в том же районе (4digit postcode)\n",
        "*  Средняя стомость 10 проданных домов после текущего в том же районе (4digit postcode)\n",
        "*  Стоимость последнего проданного дома до текущего\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df.createOrReplaceTempView('df')"
      ],
      "metadata": {
        "id": "RaPjqI9iQDQn"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "spark.sql('''\n",
        "SELECT\n",
        "  postcode,\n",
        "  datesold,\n",
        "  AVG(price) OVER (ORDER BY postcode, datesold ROWS BETWEEN 10 PRECEDING AND 1 PRECEDING) AS AVG_PRICE_10_BEFORE,\n",
        "  AVG(price) OVER (ORDER BY postcode, datesold ROWS BETWEEN 1 FOLLOWING AND 10 FOLLOWING) AS AVG_PRICE_10_AFTER,\n",
        "  SUM(price) OVER (ORDER BY postcode, datesold ROWS BETWEEN 1 PRECEDING AND 1 PRECEDING) AS PRICE_BEFORE\n",
        "FROM df\n",
        "ORDER BY postcode, datesold;''').show()"
      ],
      "metadata": {
        "id": "1XVIUjY0XgyX",
        "outputId": "060ba9ad-5e7d-4b65-8b08-1becda76adf1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+--------+-------------------+-------------------+------------------+------------+\n",
            "|postcode|           datesold|AVG_PRICE_10_BEFORE|AVG_PRICE_10_AFTER|PRICE_BEFORE|\n",
            "+--------+-------------------+-------------------+------------------+------------+\n",
            "|    2600|2007-07-08 00:00:00|               null|          708350.0|        null|\n",
            "|    2600|2007-08-16 00:00:00|           327000.0|          698350.0|      327000|\n",
            "|    2600|2007-12-05 00:00:00|           558500.0|          679350.0|      790000|\n",
            "|    2600|2008-01-21 00:00:00|  647333.3333333334|          742850.0|      825000|\n",
            "|    2600|2008-04-24 00:00:00|           564250.0|          786600.0|      315000|\n",
            "|    2600|2008-05-30 00:00:00|           509900.0|          839200.0|      292500|\n",
            "|    2600|2008-06-19 00:00:00|           479750.0|          868450.0|      329000|\n",
            "|    2600|2008-07-29 00:00:00|           520500.0|          805750.0|      765000|\n",
            "|    2600|2008-09-02 00:00:00|           571312.5|          715250.0|      927000|\n",
            "|    2600|2008-09-08 00:00:00|  661166.6666666666|          756250.0|     1380000|\n",
            "|    2600|2008-09-17 00:00:00|           669050.0|          741750.0|      740000|\n",
            "|    2600|2008-09-22 00:00:00|           708350.0|          730550.0|      720000|\n",
            "|    2600|2008-11-18 00:00:00|           698350.0|          755050.0|      690000|\n",
            "|    2600|2008-11-18 00:00:00|           679350.0|          701050.0|      635000|\n",
            "|    2600|2008-11-21 00:00:00|           742850.0|          729550.0|      950000|\n",
            "|    2600|2008-12-22 00:00:00|           786600.0|          716250.0|      730000|\n",
            "|    2600|2008-12-24 00:00:00|           839200.0|          641500.0|      855000|\n",
            "|    2600|2009-01-06 00:00:00|           868450.0|          672500.0|     1057500|\n",
            "|    2600|2009-01-12 00:00:00|           805750.0|          689000.0|      300000|\n",
            "|    2600|2009-01-20 00:00:00|           715250.0|          641500.0|      475000|\n",
            "+--------+-------------------+-------------------+------------------+------------+\n",
            "only showing top 20 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Qvh2x6_8YU3F"
      },
      "source": [
        "## Задание 2\n",
        "В итоге у вас таблица с колонками (или нечто похожее):\n",
        "*   price\n",
        "*   Среднегодовая цена\n",
        "*  Средняя стомость 10 проданных домов до текущего в том же районе (4digit postcode) (1 балл)\n",
        "*  Средняя стомость 10 проданных домов после текущего в том же районе (4digit postcode) (1 балл)\n",
        "*  Стоимость последнего проданного дома до текущего ((1 балл)\n",
        "*  и др.\n",
        "\n",
        "Посчитайте кол-во уникальных значений в каждой строчке (unique(row)) (ипользуйте udf). Попробуйте сделать то же самое используя pandas udf."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "prices = spark.sql('''\n",
        "SELECT\n",
        "  postcode,\n",
        "  datesold,\n",
        "  AVG(price) OVER (ORDER BY YEAR(datesold)) AS AVG_PRICE_YEAR,\n",
        "  AVG(price) OVER (ORDER BY postcode, datesold ROWS BETWEEN 10 PRECEDING AND 1 PRECEDING) AS AVG_PRICE_10_BEFORE,\n",
        "  AVG(price) OVER (ORDER BY postcode, datesold ROWS BETWEEN 1 FOLLOWING AND 10 FOLLOWING) AS AVG_PRICE_10_AFTER,\n",
        "  SUM(price) OVER (ORDER BY postcode, datesold ROWS BETWEEN 1 PRECEDING AND 1 PRECEDING) AS PRICE_BEFORE\n",
        "FROM df\n",
        "ORDER BY postcode, datesold;''')\n",
        "\n",
        "# Я не совсем понимаю, что тут конкретно нужно сделать и как к этому прикрутить udf. \n",
        "# Буду очень признателен, если вы напишете в комментарии к ДЗ пример кода, который нужно было написать, спасибо!"
      ],
      "metadata": {
        "id": "s0dt6k74UAWa"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pmSZTI9PAwQb"
      },
      "source": [
        "# Задание 3\n",
        "SQL like case when или if elif else\n",
        "\n",
        "Создайте колонку, в которой в которой будет отображаться \"+\", \"-\" или \"=\", если \"Средняя стомость 10 проданных домов до текущего в том же районе\" больше, меньше или равно \"Средняя стомость 10 проданных домов после текущего в том же районе (4digit postcode)\", соотвественно.\n",
        "\n",
        "Если одно из полей Null, запишите в эту колонку \"Нет данных\""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c3pfUThFQtE6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cbff8e90-2ecf-421f-8d8b-615fc538d777"
      },
      "source": [
        "spark.sql('''\n",
        "SELECT\n",
        "  postcode,\n",
        "  datesold,\n",
        "  AVG(price) OVER (ORDER BY postcode, datesold ROWS BETWEEN 10 PRECEDING AND 1 PRECEDING) AS AVG_PRICE_10_BEFORE,\n",
        "  AVG(price) OVER (ORDER BY postcode, datesold ROWS BETWEEN 1 FOLLOWING AND 10 FOLLOWING) AS AVG_PRICE_10_AFTER,\n",
        "  CASE\n",
        "  WHEN AVG_PRICE_10_BEFORE IS NULL OR \n",
        "      AVG_PRICE_10_AFTER IS NULL THEN 'Нет данных'\n",
        "  WHEN AVG_PRICE_10_BEFORE > AVG_PRICE_10_AFTER THEN \"+\"\n",
        "  WHEN AVG_PRICE_10_BEFORE < AVG_PRICE_10_AFTER THEN \"-\"\n",
        "  WHEN AVG_PRICE_10_BEFORE = AVG_PRICE_10_AFTER THEN \"=\"\n",
        "  END as price_comparison  \n",
        "FROM df\n",
        "ORDER BY postcode, datesold;''').show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+--------+-------------------+-------------------+------------------+----------------+\n",
            "|postcode|           datesold|AVG_PRICE_10_BEFORE|AVG_PRICE_10_AFTER|price_comparison|\n",
            "+--------+-------------------+-------------------+------------------+----------------+\n",
            "|    2600|2007-07-08 00:00:00|               null|          708350.0|      Нет данных|\n",
            "|    2600|2007-08-16 00:00:00|           327000.0|          698350.0|               -|\n",
            "|    2600|2007-12-05 00:00:00|           558500.0|          679350.0|               -|\n",
            "|    2600|2008-01-21 00:00:00|  647333.3333333334|          742850.0|               -|\n",
            "|    2600|2008-04-24 00:00:00|           564250.0|          786600.0|               -|\n",
            "|    2600|2008-05-30 00:00:00|           509900.0|          839200.0|               -|\n",
            "|    2600|2008-06-19 00:00:00|           479750.0|          868450.0|               -|\n",
            "|    2600|2008-07-29 00:00:00|           520500.0|          805750.0|               -|\n",
            "|    2600|2008-09-02 00:00:00|           571312.5|          715250.0|               -|\n",
            "|    2600|2008-09-08 00:00:00|  661166.6666666666|          756250.0|               -|\n",
            "|    2600|2008-09-17 00:00:00|           669050.0|          741750.0|               -|\n",
            "|    2600|2008-09-22 00:00:00|           708350.0|          730550.0|               -|\n",
            "|    2600|2008-11-18 00:00:00|           698350.0|          755050.0|               -|\n",
            "|    2600|2008-11-18 00:00:00|           679350.0|          701050.0|               -|\n",
            "|    2600|2008-11-21 00:00:00|           742850.0|          729550.0|               +|\n",
            "|    2600|2008-12-22 00:00:00|           786600.0|          716250.0|               +|\n",
            "|    2600|2008-12-24 00:00:00|           839200.0|          641500.0|               +|\n",
            "|    2600|2009-01-06 00:00:00|           868450.0|          672500.0|               +|\n",
            "|    2600|2009-01-12 00:00:00|           805750.0|          689000.0|               +|\n",
            "|    2600|2009-01-20 00:00:00|           715250.0|          641500.0|               +|\n",
            "+--------+-------------------+-------------------+------------------+----------------+\n",
            "only showing top 20 rows\n",
            "\n"
          ]
        }
      ]
    }
  ]
}