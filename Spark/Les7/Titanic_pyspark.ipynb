{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install pyspark"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vn0TiQ6Ozjm9",
        "outputId": "19a89078-9ac0-4796-aca4-1690066adb4b"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting pyspark\n",
            "  Downloading pyspark-3.4.0.tar.gz (310.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m310.8/310.8 MB\u001b[0m \u001b[31m4.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: py4j==0.10.9.7 in /usr/local/lib/python3.10/dist-packages (from pyspark) (0.10.9.7)\n",
            "Building wheels for collected packages: pyspark\n",
            "  Building wheel for pyspark (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pyspark: filename=pyspark-3.4.0-py2.py3-none-any.whl size=311317130 sha256=4d8e198afa9ec213f0efefbe7707eddb8ed066190c5db4a76b4f80ddc011d937\n",
            "  Stored in directory: /root/.cache/pip/wheels/7b/1b/4b/3363a1d04368e7ff0d408e57ff57966fcdf00583774e761327\n",
            "Successfully built pyspark\n",
            "Installing collected packages: pyspark\n",
            "Successfully installed pyspark-3.4.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "chuou4bRzLxi",
        "outputId": "e30ec940-07c9-4b78-d5cb-992ece889c55"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-----------+--------+------+--------------------+------+----+-----+-----+----------------+-------+-----+--------+\n",
            "|PassengerId|Survived|Pclass|                Name|   Sex| Age|SibSp|Parch|          Ticket|   Fare|Cabin|Embarked|\n",
            "+-----------+--------+------+--------------------+------+----+-----+-----+----------------+-------+-----+--------+\n",
            "|          1|       0|     3|Braund, Mr. Owen ...|  male|22.0|    1|    0|       A/5 21171|   7.25| null|       S|\n",
            "|          2|       1|     1|Cumings, Mrs. Joh...|female|38.0|    1|    0|        PC 17599|71.2833|  C85|       C|\n",
            "|          3|       1|     3|Heikkinen, Miss. ...|female|26.0|    0|    0|STON/O2. 3101282|  7.925| null|       S|\n",
            "|          4|       1|     1|Futrelle, Mrs. Ja...|female|35.0|    1|    0|          113803|   53.1| C123|       S|\n",
            "|          5|       0|     3|Allen, Mr. Willia...|  male|35.0|    0|    0|          373450|   8.05| null|       S|\n",
            "|          6|       0|     3|    Moran, Mr. James|  male|null|    0|    0|          330877| 8.4583| null|       Q|\n",
            "|          7|       0|     1|McCarthy, Mr. Tim...|  male|54.0|    0|    0|           17463|51.8625|  E46|       S|\n",
            "|          8|       0|     3|Palsson, Master. ...|  male| 2.0|    3|    1|          349909| 21.075| null|       S|\n",
            "|          9|       1|     3|Johnson, Mrs. Osc...|female|27.0|    0|    2|          347742|11.1333| null|       S|\n",
            "|         10|       1|     2|Nasser, Mrs. Nich...|female|14.0|    1|    0|          237736|30.0708| null|       C|\n",
            "|         11|       1|     3|Sandstrom, Miss. ...|female| 4.0|    1|    1|         PP 9549|   16.7|   G6|       S|\n",
            "|         12|       1|     1|Bonnell, Miss. El...|female|58.0|    0|    0|          113783|  26.55| C103|       S|\n",
            "|         13|       0|     3|Saundercock, Mr. ...|  male|20.0|    0|    0|       A/5. 2151|   8.05| null|       S|\n",
            "|         14|       0|     3|Andersson, Mr. An...|  male|39.0|    1|    5|          347082| 31.275| null|       S|\n",
            "|         15|       0|     3|Vestrom, Miss. Hu...|female|14.0|    0|    0|          350406| 7.8542| null|       S|\n",
            "|         16|       1|     2|Hewlett, Mrs. (Ma...|female|55.0|    0|    0|          248706|   16.0| null|       S|\n",
            "|         17|       0|     3|Rice, Master. Eugene|  male| 2.0|    4|    1|          382652| 29.125| null|       Q|\n",
            "|         18|       1|     2|Williams, Mr. Cha...|  male|null|    0|    0|          244373|   13.0| null|       S|\n",
            "|         19|       0|     3|Vander Planke, Mr...|female|31.0|    1|    0|          345763|   18.0| null|       S|\n",
            "|         20|       1|     3|Masselmani, Mrs. ...|female|null|    0|    0|            2649|  7.225| null|       C|\n",
            "+-----------+--------+------+--------------------+------+----+-----+-----+----------------+-------+-----+--------+\n",
            "only showing top 20 rows\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# Starting the Spark Session\n",
        "from pyspark.sql import SparkSession\n",
        "spark = SparkSession.builder.appName('Titanic').getOrCreate()\n",
        "  \n",
        "# Reading the data\n",
        "df = spark.read.csv('Titanic.csv',inferSchema=True, header=True)\n",
        "  \n",
        "# Showing the data\n",
        "df.show()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Selecting the columns which are required \n",
        "# to train and test the model.\n",
        "rm_columns = df.select(['Survived','Pclass',\n",
        "                       'Sex','Age','SibSp',\n",
        "                       'Parch','Fare','Embarked'])\n",
        "  \n",
        "# Drops the data having null values\n",
        "result = rm_columns.na.drop()\n",
        "  \n",
        "# Again showing the data\n",
        "result.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6Ok_e2euzS7x",
        "outputId": "a90050b0-297b-4731-fdab-a351bb3ddcc6"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+--------+------+------+----+-----+-----+-------+--------+\n",
            "|Survived|Pclass|   Sex| Age|SibSp|Parch|   Fare|Embarked|\n",
            "+--------+------+------+----+-----+-----+-------+--------+\n",
            "|       0|     3|  male|22.0|    1|    0|   7.25|       S|\n",
            "|       1|     1|female|38.0|    1|    0|71.2833|       C|\n",
            "|       1|     3|female|26.0|    0|    0|  7.925|       S|\n",
            "|       1|     1|female|35.0|    1|    0|   53.1|       S|\n",
            "|       0|     3|  male|35.0|    0|    0|   8.05|       S|\n",
            "|       0|     1|  male|54.0|    0|    0|51.8625|       S|\n",
            "|       0|     3|  male| 2.0|    3|    1| 21.075|       S|\n",
            "|       1|     3|female|27.0|    0|    2|11.1333|       S|\n",
            "|       1|     2|female|14.0|    1|    0|30.0708|       C|\n",
            "|       1|     3|female| 4.0|    1|    1|   16.7|       S|\n",
            "|       1|     1|female|58.0|    0|    0|  26.55|       S|\n",
            "|       0|     3|  male|20.0|    0|    0|   8.05|       S|\n",
            "|       0|     3|  male|39.0|    1|    5| 31.275|       S|\n",
            "|       0|     3|female|14.0|    0|    0| 7.8542|       S|\n",
            "|       1|     2|female|55.0|    0|    0|   16.0|       S|\n",
            "|       0|     3|  male| 2.0|    4|    1| 29.125|       Q|\n",
            "|       0|     3|female|31.0|    1|    0|   18.0|       S|\n",
            "|       0|     2|  male|35.0|    0|    0|   26.0|       S|\n",
            "|       1|     2|  male|34.0|    0|    0|   13.0|       S|\n",
            "|       1|     3|female|15.0|    0|    0| 8.0292|       Q|\n",
            "+--------+------+------+----+-----+-----+-------+--------+\n",
            "only showing top 20 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Importing the required libraries\n",
        "from pyspark.ml.feature import VectorAssembler, StringIndexer, OneHotEncoder\n",
        "  \n",
        "# Converting the Sex Column\n",
        "sexIdx = StringIndexer(inputCol='Sex',\n",
        "                               outputCol='SexIndex')\n",
        "sexEncode = OneHotEncoder(inputCol='SexIndex',\n",
        "                               outputCol='SexVec')\n",
        "  \n",
        "# Converting the Embarked Column\n",
        "embarkIdx = StringIndexer(inputCol='Embarked',\n",
        "                               outputCol='EmbarkIndex')\n",
        "embarkEncode = OneHotEncoder(inputCol='EmbarkIndex',\n",
        "                               outputCol='EmbarkVec')\n",
        "  \n",
        "# Vectorizing the data into a new column \"features\" \n",
        "# which will be our input/features class\n",
        "assembler = VectorAssembler(inputCols=['Pclass',\n",
        "                                       'SexVec','Age',\n",
        "                                       'SibSp','Parch',\n",
        "                                       'Fare','EmbarkVec'],\n",
        "                                    outputCol='features')"
      ],
      "metadata": {
        "id": "lu5EwM0wzV1-"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Importing Pipeline and Model\n",
        "from pyspark.ml import Pipeline\n",
        "from pyspark.ml.classification import LogisticRegression\n",
        "  \n",
        "log_reg = LogisticRegression(featuresCol='features',\n",
        "                             labelCol='Survived')\n",
        "  \n",
        "# Creating the pipeline\n",
        "pipe = Pipeline(stages=[sexIdx, embarkIdx,\n",
        "                            sexEncode, embarkEncode,\n",
        "                            assembler, log_reg])"
      ],
      "metadata": {
        "id": "7uET5lIFzYp_"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Splitting the data into train and test\n",
        "train_data, test_data = result.randomSplit([0.7, .3])\n",
        "  \n",
        "# Fitting the model on training data\n",
        "fit_model = pipe.fit(train_data)\n",
        "  \n",
        "# Storing the results on test data\n",
        "results = fit_model.transform(test_data)\n",
        "  \n",
        "# Showing the results\n",
        "results.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TVFGtFv7zauw",
        "outputId": "f5cbfe14-1246-45cc-b8dd-16326ed86ad4"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+--------+------+------+----+-----+-----+--------+--------+--------+-----------+-------------+-------------+--------------------+--------------------+--------------------+----------+\n",
            "|Survived|Pclass|   Sex| Age|SibSp|Parch|    Fare|Embarked|SexIndex|EmbarkIndex|       SexVec|    EmbarkVec|            features|       rawPrediction|         probability|prediction|\n",
            "+--------+------+------+----+-----+-----+--------+--------+--------+-----------+-------------+-------------+--------------------+--------------------+--------------------+----------+\n",
            "|       0|     1|female| 2.0|    1|    2|  151.55|       S|     1.0|        0.0|    (1,[],[])|(2,[0],[1.0])|[1.0,0.0,2.0,1.0,...|[-3.9627611998561...|[0.01865589108011...|       1.0|\n",
            "|       0|     1|  male|19.0|    3|    2|   263.0|       S|     0.0|        0.0|(1,[0],[1.0])|(2,[0],[1.0])|[1.0,1.0,19.0,3.0...|[-0.4616365617106...|[0.38659765781280...|       1.0|\n",
            "|       0|     1|  male|21.0|    0|    1| 77.2875|       S|     0.0|        0.0|(1,[0],[1.0])|(2,[0],[1.0])|[1.0,1.0,21.0,0.0...|[-0.5131171698603...|[0.37446307291824...|       1.0|\n",
            "|       0|     1|  male|24.0|    0|    0|    79.2|       C|     0.0|        1.0|(1,[0],[1.0])|(2,[1],[1.0])|[1.0,1.0,24.0,0.0...|[-0.6930736620894...|[0.33334967097140...|       1.0|\n",
            "|       0|     1|  male|27.0|    0|    2|   211.5|       C|     0.0|        1.0|(1,[0],[1.0])|(2,[1],[1.0])|[1.0,1.0,27.0,0.0...|[-1.2218530166862...|[0.22761051846420...|       1.0|\n",
            "|       0|     1|  male|33.0|    0|    0|     5.0|       S|     0.0|        0.0|(1,[0],[1.0])|(2,[0],[1.0])|[1.0,1.0,33.0,0.0...|[0.31161274713058...|[0.57727886552174...|       0.0|\n",
            "|       0|     1|  male|38.0|    0|    1|153.4625|       S|     0.0|        0.0|(1,[0],[1.0])|(2,[0],[1.0])|[1.0,1.0,38.0,0.0...|[-0.0944353670842...|[0.47640868797610...|       1.0|\n",
            "|       0|     1|  male|45.5|    0|    0|    28.5|       S|     0.0|        0.0|(1,[0],[1.0])|(2,[0],[1.0])|[1.0,1.0,45.5,0.0...|[0.73064743655628...|[0.67494733199549...|       0.0|\n",
            "|       0|     1|  male|46.0|    0|    0|    79.2|       C|     0.0|        1.0|(1,[0],[1.0])|(2,[1],[1.0])|[1.0,1.0,46.0,0.0...|[0.18586930701849...|[0.54633401020208...|       0.0|\n",
            "|       0|     1|  male|47.0|    0|    0| 25.5875|       S|     0.0|        0.0|(1,[0],[1.0])|(2,[0],[1.0])|[1.0,1.0,47.0,0.0...|[0.80053546248507...|[0.69008901009218...|       0.0|\n",
            "|       0|     1|  male|47.0|    0|    0|    52.0|       S|     0.0|        0.0|(1,[0],[1.0])|(2,[0],[1.0])|[1.0,1.0,47.0,0.0...|[0.71021064142802...|[0.67044770219366...|       0.0|\n",
            "|       0|     1|  male|49.0|    1|    1|110.8833|       C|     0.0|        1.0|(1,[0],[1.0])|(2,[1],[1.0])|[1.0,1.0,49.0,1.0...|[0.38746894741135...|[0.59567325171877...|       0.0|\n",
            "|       0|     1|  male|51.0|    0|    1| 61.3792|       C|     0.0|        1.0|(1,[0],[1.0])|(2,[1],[1.0])|[1.0,1.0,51.0,0.0...|[0.34847275237867...|[0.58624717642035...|       0.0|\n",
            "|       0|     1|  male|54.0|    0|    0| 51.8625|       S|     0.0|        0.0|(1,[0],[1.0])|(2,[0],[1.0])|[1.0,1.0,54.0,0.0...|[0.99034453255161...|[0.72915596860777...|       0.0|\n",
            "|       0|     1|  male|56.0|    0|    0|   26.55|       S|     0.0|        0.0|(1,[0],[1.0])|(2,[0],[1.0])|[1.0,1.0,56.0,0.0...|[1.15681150681357...|[0.76075286634011...|       0.0|\n",
            "|       0|     1|  male|56.0|    0|    0| 30.6958|       C|     0.0|        1.0|(1,[0],[1.0])|(2,[1],[1.0])|[1.0,1.0,56.0,0.0...|[0.75126231445636...|[0.67945368894232...|       0.0|\n",
            "|       0|     1|  male|58.0|    0|    2| 113.275|       C|     0.0|        1.0|(1,[0],[1.0])|(2,[1],[1.0])|[1.0,1.0,58.0,0.0...|[0.35256498164730...|[0.58723944178331...|       0.0|\n",
            "|       0|     1|  male|60.0|    0|    0|   26.55|       S|     0.0|        0.0|(1,[0],[1.0])|(2,[0],[1.0])|[1.0,1.0,60.0,0.0...|[1.31661931937864...|[0.78861869948841...|       0.0|\n",
            "|       0|     1|  male|61.0|    0|    0| 32.3208|       S|     0.0|        0.0|(1,[0],[1.0])|(2,[0],[1.0])|[1.0,1.0,61.0,0.0...|[1.33683643191959...|[0.79196921242448...|       0.0|\n",
            "|       0|     1|  male|61.0|    0|    0|    33.5|       S|     0.0|        0.0|(1,[0],[1.0])|(2,[0],[1.0])|[1.0,1.0,61.0,0.0...|[1.33280383262037...|[0.79130404337904...|       0.0|\n",
            "+--------+------+------+----+-----+-----+--------+--------+--------+-----------+-------------+-------------+--------------------+--------------------+--------------------+----------+\n",
            "only showing top 20 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Importing the evaluator\n",
        "from pyspark.ml.evaluation import BinaryClassificationEvaluator\n",
        "  \n",
        "# Calling the evaluator\n",
        "res = BinaryClassificationEvaluator \\\n",
        "        (rawPredictionCol='prediction',labelCol='Survived')\n",
        "  \n",
        "# Evaluating the AUC on results\n",
        "ROC_AUC = res.evaluate(results)"
      ],
      "metadata": {
        "id": "mjdWRR1Ezcfs"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ROC_AUC"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ScmJJAchzen_",
        "outputId": "67676651-1f92-482a-971a-ed5be84b58a2"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.7209600132187707"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "3KRDyGx_1HvO"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}