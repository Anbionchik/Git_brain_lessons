#####################################################################
Задание №1: Cassandra
#####################################################################


PS C:\Users\Андрей\PycharmProjects\Git_brain_lessons\Hadoop\docker-cassandra> docker pull cassandra
Using default tag: latest
latest: Pulling from library/cassandra
846c0b181fff: Pull complete
9923132fe6ab: Pull complete
fcd5cbc3b5e5: Pull complete
4d78778bf6ee: Pull complete
8a46c9313733: Pull complete
200797bd56b8: Pull complete
33d4c6e1eee9: Pull complete
ff00f670cf06: Pull complete
e22ff0b1ed21: Pull complete
Digest: sha256:566489b615eec3d43427f73d986aaa9568ff88f3a83ac6bea2175f5bfcd2469d
Status: Downloaded newer image for cassandra:latest
docker.io/library/cassandra:latest
PS C:\Users\Андрей\PycharmProjects\Git_brain_lessons\Hadoop\docker-cassandra> docker run --name test_cassandra --network localhost -d cassandra:4.0
Unable to find image 'cassandra:4.0' locally
4.0: Pulling from library/cassandra
846c0b181fff: Already exists
9923132fe6ab: Already exists
fcd5cbc3b5e5: Already exists
4d78778bf6ee: Already exists
8a46c9313733: Already exists
200797bd56b8: Already exists
33d4c6e1eee9: Already exists
a2a1be451707: Pull complete
7e7d6c7221b9: Pull complete
Digest: sha256:b0833c4da1694c4cdb78ddc567aea0cafafe4316ba375b12e374211def71b3c9
Status: Downloaded newer image for cassandra:4.0
6e281f6b6f40aaa03d5b669bbb52da2f8c3c0859fe78e7be5bdeb4b7c3e38a2e
docker: Error response from daemon: network localhost not found.
PS C:\Users\Андрей\PycharmProjects\Git_brain_lessons\Hadoop\docker-cassandra> docker run --name test_cassandra --network some-network -d cassandra:4.0
docker: Error response from daemon: Conflict. The container name "/test_cassandra" is already in use by container "6e281f6b6f40aaa03d5b669bbb52da2f8c3c0859fe78e7be5bdeb4b7c3e38a2e". You have to remove (or rename) that container to be able to reuse that name.
See 'docker run --help'.
PS C:\Users\Андрей\PycharmProjects\Git_brain_lessons\Hadoop\docker-cassandra> docker networok create cassandra          docker: 'networok' is not a docker command.
See 'docker --help'
PS C:\Users\Андрей\PycharmProjects\Git_brain_lessons\Hadoop\docker-cassandra> docker netwrok create cassandra
docker: 'netwrok' is not a docker command.
See 'docker --help'
PS C:\Users\Андрей\PycharmProjects\Git_brain_lessons\Hadoop\docker-cassandra> docker network create cassandra
bb98530b51ea3cd7bdefbba9d46d2133ef3e81c1e94ef07c8b24c02ce6485094
PS C:\Users\Андрей\PycharmProjects\Git_brain_lessons\Hadoop\docker-cassandra> docker run --rm -d --name cassandra --hostname cassandra --network cassandra cassandra
3fa65cbb5b822b6b7e0e55b3b088715cd6fe08c4356330165532ba980e837901
PS C:\Users\Андрей\PycharmProjects\Git_brain_lessons\Hadoop\docker-cassandra> docker run -it --network cassandra --rm cassandra cqlsh cassandra
Connected to Test Cluster at cassandra:9042
[cqlsh 6.1.0 | Cassandra 4.1.0 | CQL spec 3.4.6 | Native protocol v5]
Use HELP for help.
cqlsh> CREATE KEYSPACE IF NOT EXISTS store WITH REPLICATION = { 'class' : 'SimpleStrategy', 'replication_factor' : '1' };
cqlsh> create table if not exists store.shopping_cart ( userid text PRIMARY key, item_count int, last_update_timestamp timestamp);
cqlsh> insert into store.shopping_cart
   ... (userid, item_count, last_update_timestamp)
   ... values ('9876', 2, toTimeStamp(now()));
cqlsh> insert into store.shopping_cart (userid, item_count, last_update_timestamp) values ('1234', 5, toTimeStamp(now())
);
cqlsh> select * from store.shopping_cart
   ... ;

 userid | item_count | last_update_timestamp
--------+------------+---------------------------------
   1234 |          5 | 2022-12-19 18:24:27.863000+0000
   9876 |          2 | 2022-12-19 18:24:12.554000+0000

(2 rows)
cqlsh>



#####################################################################
Задание №2: Hbase
#####################################################################



# whoami
root
# hbase shell
2022-12-20 16:41:45,190 WARN  [main] util.NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
HBase Shell; enter 'help<RETURN>' for list of supported commands.
Type "exit<RETURN>" to leave the HBase Shell
Version 1.2.6, rUnknown, Mon May 29 02:25:32 CDT 2017

hbase(main):001:0> help
HBase Shell, version 1.2.6, rUnknown, Mon May 29 02:25:32 CDT 2017
Type 'help "COMMAND"', (e.g. 'help "get"' -- the quotes are necessary) for help on a specific command.
Commands are grouped. Type 'help "COMMAND_GROUP"', (e.g. 'help "general"') for help on a command group.

COMMAND GROUPS:
  Group name: general
  Commands: status, table_help, version, whoami

  Group name: ddl
  Commands: alter, alter_async, alter_status, create, describe, disable, disable_all, drop, drop_all, enable, enable_all, exists, get_table, is_disabled, is_enabled, list, locate_region, show_filters

  Group name: namespace
  Commands: alter_namespace, create_namespace, describe_namespace, drop_namespace, list_namespace, list_namespace_tables

  Group name: dml
  Commands: append, count, delete, deleteall, get, get_counter, get_splits, incr, put, scan, truncate, truncate_preserve

  Group name: tools
  Commands: assign, balance_switch, balancer, balancer_enabled, catalogjanitor_enabled, catalogjanitor_run, catalogjanitor_switch, close_region, compact, compact_rs, flush, major_compact, merge_region, move, normalize, normalizer_enabled, normalizer_switch, split, trace, unassign, wal_roll, zk_dump

  Group name: replication
  Commands: add_peer, append_peer_tableCFs, disable_peer, disable_table_replication, enable_peer, enable_table_replication, list_peers, list_replicated_tables, remove_peer, remove_peer_tableCFs, set_peer_tableCFs, show_peer_tableCFs

  Group name: snapshots
  Commands: clone_snapshot, delete_all_snapshot, delete_snapshot, list_snapshots, restore_snapshot, snapshot

  Group name: configuration
  Commands: update_all_config, update_config

  Group name: quotas
  Commands: list_quotas, set_quota

  Group name: security
  Commands: grant, list_security_capabilities, revoke, user_permission

  Group name: procedures
  Commands: abort_procedure, list_procedures

  Group name: visibility labels
  Commands: add_labels, clear_auths, get_auths, list_labels, set_auths, set_visibility

SHELL USAGE:
Quote all names in HBase Shell such as table and column names.  Commas delimit
command parameters.  Type <RETURN> after entering a command to run it.
Dictionaries of configuration used in the creation and alteration of tables are
Ruby Hashes. They look like this:

  {'key1' => 'value1', 'key2' => 'value2', ...}

and are opened and closed with curley-braces.  Key/values are delimited by the
'=>' character combination.  Usually keys are predefined constants such as
NAME, VERSIONS, COMPRESSION, etc.  Constants do not need to be quoted.  Type
'Object.constants' to see a (messy) list of all constants in the environment.

If you are using binary keys or values and need to enter them in the shell, use
double-quote'd hexadecimal representation. For example:

  hbase> get 't1', "key\x03\x3f\xcd"
  hbase> get 't1', "key\003\023\011"
  hbase> put 't1', "test\xef\xff", 'f1:', "\x01\x33\x40"

The HBase shell is the (J)Ruby IRB with the above HBase-specific commands added.
For more on the HBase Shell, see http://hbase.apache.org/book.html
hbase(main):002:0> create 'test', 'cf'
0 row(s) in 2.4390 seconds

=> Hbase::Table - test
hbase(main):003:0> list 'test'
TABLE                                                                                                                                                                                           
test                                                                                                                                                                                            
1 row(s) in 0.0170 seconds

=> ["test"]
hbase(main):004:0> describe 'test'
Table test is ENABLED                                                                                                                                                                           
test                                                                                                                                                                                            
COLUMN FAMILIES DESCRIPTION                                                                                                                                                                     
{NAME => 'cf', BLOOMFILTER => 'ROW', VERSIONS => '1', IN_MEMORY => 'false', KEEP_DELETED_CELLS => 'FALSE', DATA_BLOCK_ENCODING => 'NONE', TTL => 'FOREVER', COMPRESSION => 'NONE', MIN_VERSIONS 
=> '0', BLOCKCACHE => 'true', BLOCKSIZE => '65536', REPLICATION_SCOPE => '0'}                                                                                                                   
1 row(s) in 0.0800 seconds

hbase(main):005:0> put 'test', 'row1', 'cf:a', 'value1'
0 row(s) in 0.0690 seconds

hbase(main):006:0> put 'test', 'row2', 'cf:b', 3615564
0 row(s) in 0.0080 seconds

hbase(main):007:0> scan 'test1'
ROW                                               COLUMN+CELL                                                                                                                                   

ERROR: Unknown table test1!

Here is some help for this command:
Scan a table; pass table name and optionally a dictionary of scanner
specifications.  Scanner specifications may include one or more of:
TIMERANGE, FILTER, LIMIT, STARTROW, STOPROW, ROWPREFIXFILTER, TIMESTAMP,
MAXLENGTH or COLUMNS, CACHE or RAW, VERSIONS, ALL_METRICS or METRICS

If no columns are specified, all columns will be scanned.
To scan all members of a column family, leave the qualifier empty as in
'col_family'.

The filter can be specified in two ways:
1. Using a filterString - more information on this is available in the
Filter Language document attached to the HBASE-4176 JIRA
2. Using the entire package name of the filter.

If you wish to see metrics regarding the execution of the scan, the
ALL_METRICS boolean should be set to true. Alternatively, if you would
prefer to see only a subset of the metrics, the METRICS array can be 
defined to include the names of only the metrics you care about.

Some examples:

  hbase> scan 'hbase:meta'
  hbase> scan 'hbase:meta', {COLUMNS => 'info:regioninfo'}
  hbase> scan 'ns1:t1', {COLUMNS => ['c1', 'c2'], LIMIT => 10, STARTROW => 'xyz'}
  hbase> scan 't1', {COLUMNS => ['c1', 'c2'], LIMIT => 10, STARTROW => 'xyz'}
  hbase> scan 't1', {COLUMNS => 'c1', TIMERANGE => [1303668804, 1303668904]}
  hbase> scan 't1', {REVERSED => true}
  hbase> scan 't1', {ALL_METRICS => true}
  hbase> scan 't1', {METRICS => ['RPC_RETRIES', 'ROWS_FILTERED']}
  hbase> scan 't1', {ROWPREFIXFILTER => 'row2', FILTER => "
    (QualifierFilter (>=, 'binary:xyz')) AND (TimestampsFilter ( 123, 456))"}
  hbase> scan 't1', {FILTER =>
    org.apache.hadoop.hbase.filter.ColumnPaginationFilter.new(1, 0)}
  hbase> scan 't1', {CONSISTENCY => 'TIMELINE'}
For setting the Operation Attributes 
  hbase> scan 't1', { COLUMNS => ['c1', 'c2'], ATTRIBUTES => {'mykey' => 'myvalue'}}
  hbase> scan 't1', { COLUMNS => ['c1', 'c2'], AUTHORIZATIONS => ['PRIVATE','SECRET']}
For experts, there is an additional option -- CACHE_BLOCKS -- which
switches block caching for the scanner on (true) or off (false).  By
default it is enabled.  Examples:

  hbase> scan 't1', {COLUMNS => ['c1', 'c2'], CACHE_BLOCKS => false}

Also for experts, there is an advanced option -- RAW -- which instructs the
scanner to return all cells (including delete markers and uncollected deleted
cells). This option cannot be combined with requesting specific COLUMNS.
Disabled by default.  Example:

  hbase> scan 't1', {RAW => true, VERSIONS => 10}

Besides the default 'toStringBinary' format, 'scan' supports custom formatting
by column.  A user can define a FORMATTER by adding it to the column name in
the scan specification.  The FORMATTER can be stipulated: 

 1. either as a org.apache.hadoop.hbase.util.Bytes method name (e.g, toInt, toString)
 2. or as a custom class followed by method name: e.g. 'c(MyFormatterClass).format'.

Example formatting cf:qualifier1 and cf:qualifier2 both as Integers: 
  hbase> scan 't1', {COLUMNS => ['cf:qualifier1:toInt',
    'cf:qualifier2:c(org.apache.hadoop.hbase.util.Bytes).toInt'] } 

Note that you can specify a FORMATTER by column only (cf:qualifier).  You cannot
specify a FORMATTER for all columns of a column family.

Scan can also be used directly from a table, by first getting a reference to a
table, like such:

  hbase> t = get_table 't'
  hbase> t.scan

Note in the above situation, you can still provide all the filtering, columns,
options, etc as described above.



hbase(main):008:0> scan 'test'
ROW                                               COLUMN+CELL                                                                                                                                   
 row1                                             column=cf:a, timestamp=1671555689155, value=value1                                                                                            
 row2                                             column=cf:b, timestamp=1671555708462, value=3615564                                                                                           
2 row(s) in 0.0120 seconds

hbase(main):009:0> put 'test', 'row2', 'cf:a', 36164
0 row(s) in 0.0050 seconds

hbase(main):010:0> scan 'test'
ROW                                               COLUMN+CELL                                                                                                                                   
 row1                                             column=cf:a, timestamp=1671555689155, value=value1                                                                                            
 row2                                             column=cf:a, timestamp=1671555748182, value=36164                                                                                             
 row2                                             column=cf:b, timestamp=1671555708462, value=3615564                                                                                           
2 row(s) in 0.0100 seconds

hbase(main):011:0> get 'test', 'row2'
COLUMN                                            CELL                                                                                                                                          
 cf:a                                             timestamp=1671555748182, value=36164                                                                                                          
 cf:b                                             timestamp=1671555708462, value=3615564                                                                                                        
2 row(s) in 0.0170 seconds

hbase(main):012:0> put 'test', 'row2', 'cf:a', 361
0 row(s) in 0.0050 seconds

hbase(main):013:0> get 'test', 'row2'
COLUMN                                            CELL                                                                                                                                          
 cf:a                                             timestamp=1671555782346, value=361                                                                                                            
 cf:b                                             timestamp=1671555708462, value=3615564                                                                                                        
2 row(s) in 0.0070 seconds

hbase(main):014:0> disable 'test'
0 row(s) in 2.3140 seconds

hbase(main):015:0> drop 'test'
0 row(s) in 1.2760 seconds

hbase(main):016:0> quit